{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/code/markuslhde/brain-alzheimer-prediction-with-pytorch/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing PyTorch, torchvision, and other libraries needed for the task\n",
    "\n",
    "import torch  # PyTorch for building and training neural networks\n",
    "\n",
    "from torchvision.datasets import ImageFolder  # To load images from a folder structure\n",
    "\n",
    "from torchvision import transforms  # For applying transformations (e.g., resizing, normalizing) to the images\n",
    "\n",
    "from torch.utils.data import dataloader, DataLoader  # To create data loaders for training and testing\n",
    "\n",
    "import matplotlib.pyplot as plt  # For plotting graphs (like loss/accuracy over time)\n",
    "\n",
    "from torch import optim  # PyTorch's optimization module for updating weights\n",
    "\n",
    "from torch import nn  # PyTorch's neural network module, used to define layers\n",
    "\n",
    "# Importing specific metrics from torchmetrics\n",
    "\n",
    "from torchmetrics import Recall, Precision, Accuracy, AUROC  # Metrics to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Defining transformations to apply to the training images\n",
    "\n",
    "train_transform = transforms.Compose([  # Compose allows stacking multiple transformations together\n",
    "\n",
    "    transforms.ToTensor(),  # Converts images to PyTorch tensors (from 0-255 range to 0-1 float range)\n",
    "\n",
    "    transforms.Resize((64, 64)),  # Resizes the images to 64x64 pixels\n",
    "\n",
    "])\n",
    "\n",
    "# Defining transformations to apply to the test images\n",
    "\n",
    "test_transform = transforms.Compose([  # Similar transformations for test images to ensure consistency\n",
    "\n",
    "    transforms.ToTensor(),  # Converts images to PyTorch tensors\n",
    "\n",
    "    transforms.Resize((64, 64))  # Resizes test images to 64x64 pixels\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the training dataset from the specified folder\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "\n",
    "    '/kaggle/input/best-alzheimer-mri-dataset-99-accuracy/Combined Dataset/train',  # Path to the training dataset\n",
    "\n",
    "    transform=train_transform  # Applying the defined transformations (ToTensor and Resize) to the training data\n",
    "\n",
    ")\n",
    "\n",
    "# Loading the testing dataset from the specified folder\n",
    "\n",
    "dataset_test = ImageFolder(\n",
    "\n",
    "    '/kaggle/input/best-alzheimer-mri-dataset-99-accuracy/Combined Dataset/test',  # Path to the test dataset\n",
    "\n",
    "    transform=test_transform  # Applying the defined transformations to the test data\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a DataLoader for the training dataset\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,  # The training dataset loaded using ImageFolder\n",
    "\n",
    "                              batch_size=32,  # Number of images to be passed through the network at once\n",
    "\n",
    "                              shuffle=True  # Randomly shuffle the data at each epoch for better training\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Creating a DataLoader for the test dataset\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test,  # The test dataset loaded using ImageFolder\n",
    "\n",
    "                             batch_size=32,  # The same batch size as training to ensure consistency\n",
    "\n",
    "                             shuffle=True  # Optionally shuffle test data (can be False, but True here for demonstration)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fetching one batch of data from the training DataLoader\n",
    "\n",
    "images, labels = next(iter(dataloader_train))  # 'iter' turns the DataLoader into an iterator, and 'next' gives the next batch\n",
    "\n",
    "print(images.shape)  # Printing the shape of the image batch (e.g., [32, 3, 64, 64]), where:\n",
    "\n",
    "# 32 = batch size, 3 = number of color channels (RGB), 64x64 = image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the first image from the batch of images\n",
    "\n",
    "image = images[0]  # Accessing the first image tensor in the batch\n",
    "\n",
    "\n",
    "\n",
    "# Squeezing the tensor to remove any singleton dimensions (e.g., if the tensor shape is [1, 3, 64, 64])\n",
    "\n",
    "image = image.squeeze().permute(1, 2, 0)  # Permuting the dimensions to [height, width, channels] for display\n",
    "\n",
    "\n",
    "\n",
    "# Displaying the image using matplotlib\n",
    "\n",
    "plt.imshow(image)  # Displaying the image; Matplotlib expects channels last format (H, W, C)\n",
    "\n",
    "plt.show()  # Rendering the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Defining a neural network architecture by subclassing nn.Module\n",
    "\n",
    "class Net(nn.Module): \n",
    "\n",
    "    def __init__(self, num_classes):  # Constructor method that initializes the network\n",
    "\n",
    "        super().__init__()  # Calling the parent class (nn.Module) constructor\n",
    "\n",
    "        # Defining the feature extractor part of the network\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=1),  # Convolutional layer: 3 input channels (RGB), 32 output channels\n",
    "\n",
    "            nn.ELU(),  # Activation function to introduce non-linearity\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),  # Max pooling layer to reduce spatial dimensions\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=2, padding=1),  # Second convolutional layer: 32 input channels, 64 output channels\n",
    "\n",
    "            nn.ELU(),  # Another activation function\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),  # Second max pooling layer\n",
    "\n",
    "            nn.Flatten()  # Flattening the output to feed into the fully connected layer\n",
    "\n",
    "        )\n",
    "\n",
    "        # Defining the classifier part of the network: a fully connected layer\n",
    "\n",
    "        self.classifier = nn.Linear(64 * 16 * 16, num_classes)  # Takes flattened features and outputs class scores\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):  # Forward pass through the network\n",
    "\n",
    "        x = self.feature_extractor(x)  # Passing input through the feature extractor\n",
    "\n",
    "        x = self.classifier(x)  # Passing extracted features to the classifier\n",
    "\n",
    "        return x  # Returning the output (class scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the neural network with the specified number of output classes\n",
    "\n",
    "net = Net(num_classes=4)  # Creating an instance of the Net class with 4 output classes (e.g., for a 4-class classification problem)\n",
    "\n",
    "\n",
    "\n",
    "# Defining the loss function for training\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Cross entropy loss is commonly used for multi-class classification problems\n",
    "\n",
    "\n",
    "\n",
    "# Initializing the optimizer for updating network weights\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Using the Adam optimizer with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing metrics for model evaluation\n",
    "\n",
    "\n",
    "\n",
    "# Metric for recall: Measures the ability of the model to find all relevant instances (true positives)\n",
    "\n",
    "metric_recall = Recall(task='multiclass', num_classes=4, average='macro')  # 'macro' averages recall across all classes equally\n",
    "\n",
    "\n",
    "\n",
    "# Metric for precision: Measures the ability of the model to identify only relevant instances (true positives among all predicted positives)\n",
    "\n",
    "metric_precision = Precision(task='multiclass', num_classes=4, average='macro')  # 'macro' averages precision across all classes equally\n",
    "\n",
    "\n",
    "\n",
    "# Metric for accuracy: Measures the overall correctness of the model's predictions\n",
    "\n",
    "metric_accuracy = Accuracy(task='multiclass', num_classes=4, average='macro')  # 'macro' averages accuracy across all classes equally\n",
    "\n",
    "\n",
    "\n",
    "# Metric for recall with no averaging: Provides recall for each class individually\n",
    "\n",
    "metric_recall_m = Recall(task='multiclass', num_classes=4, average=None)  # 'None' returns recall for each class separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training and evaluation loop for the model\n",
    "\n",
    "for epoch in range(10):  # Looping through the specified number of epochs\n",
    "\n",
    "    net.train()  # Set the model to training mode\n",
    "\n",
    "    # Iterating through the training dataset\n",
    "\n",
    "    for images, labels in dataloader_train:\n",
    "\n",
    "        optimizer.zero_grad()  # Resetting the gradients for the optimizer\n",
    "\n",
    "        output = net(images)  # Forward pass: getting model predictions for the current batch\n",
    "\n",
    "        loss = criterion(output, labels)  # Calculating the loss using the predicted and actual labels\n",
    "\n",
    "        loss.backward()  # Backward pass: computing gradients\n",
    "\n",
    "        optimizer.step()  # Updating the model parameters\n",
    "\n",
    "\n",
    "\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "\n",
    "        # Iterating through the test dataset\n",
    "\n",
    "        for images, labels in dataloader_test:\n",
    "\n",
    "            output = net(images)  # Forward pass: getting predictions for the test batch\n",
    "\n",
    "            _, pred = torch.max(output, 1)  # Getting the predicted class labels (index of max logit)\n",
    "\n",
    "            # Updating metrics with the predictions and actual labels\n",
    "\n",
    "            metric_accuracy(pred, labels)  # Computing accuracy\n",
    "\n",
    "            metric_recall(pred, labels)  # Computing recall\n",
    "\n",
    "            metric_precision(pred, labels)  # Computing precision\n",
    "\n",
    "            metric_recall_m(pred, labels)  # Computing recall for each class separately\n",
    "\n",
    "\n",
    "\n",
    "    # Computing final metrics after evaluating the test dataset\n",
    "\n",
    "    precision = metric_precision.compute()  # Get the computed precision\n",
    "\n",
    "    recall = metric_recall.compute()  # Get the computed recall\n",
    "\n",
    "    accuracy = metric_accuracy.compute()  # Get the computed accuracy\n",
    "\n",
    "    recall_m = metric_recall_m.compute()  # Get the computed recall for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Printing the evaluation metrics after completing the training and testing loop\n",
    "\n",
    "print(f'Precision: {precision}')  # Displaying the overall precision of the model\n",
    "\n",
    "print(f'Recall: {recall}')  # Displaying the overall recall of the model\n",
    "\n",
    "print(f'Accuracy: {accuracy}')  # Displaying the overall accuracy of the model\n",
    "\n",
    "print(f'Recall per class: {recall_m}')  # Displaying the recall for each class individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Accessing the class-to-index mapping for the test dataset\n",
    "\n",
    "class_to_idx = dataset_test.class_to_idx  # This returns a dictionary mapping class names to their corresponding indices\n",
    "\n",
    "print(class_to_idx)  # Print the mapping to see which class corresponds to which index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary mapping class names to their corresponding recall values\n",
    "\n",
    "recall_per_class = {\n",
    "\n",
    "    k: recall_m[v].item()  # For each class name (k), get the recall value for the corresponding index (v)\n",
    "\n",
    "    for k, v in dataset_test.class_to_idx.items()  # Iterating over the class-to-index mapping from the test dataset\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print(recall_per_class)  # Print the recall values for each class"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
